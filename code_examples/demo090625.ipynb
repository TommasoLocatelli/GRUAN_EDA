{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "254cd048",
   "metadata": {},
   "source": [
    "# GRUANpy Proof of Concept\n",
    "\n",
    "GRUANpy is a python toolkit to facilitate the analysis of GRUAN data. It includes several functionalities and is easily extensible thanks to its structure based on the inclusion of different data models and helper classes that provide specialized methods for different types of purposes. The different functions can also be executed in succession in order to create real data pipelines that allow a large variety of outputs.\n",
    "\n",
    "Here is a list of the main features identified so far:\n",
    "- download, the ability to download data of interest\n",
    "- merge, the ability to merge data from different products\n",
    "- aggregation, the ability to aggregate different observations and lower the resolution of the data (respecting the GRUAN principles in uncertainty processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edef7619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo setup\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from gruanpy import GRUANpy\n",
    "from datetime import datetime\n",
    "download_folder=r\"gdp_demo_090625\"\n",
    "gp = GRUANpy(download_folder=download_folder)\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d539f1",
   "metadata": {},
   "source": [
    "## DOWNLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab868b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75 files in pub/data/gruan/processing/level2/RS92-GDP/version-002/LIN/2018\n",
      "LIN-RS-01_2_RS92-GDP_002_20180611T180000_1-002-001.nc\n",
      "LIN-RS-01_2_RS92-GDP_002_20180103T000000_1-002-002.nc\n",
      "LIN-RS-01_2_RS92-GDP_002_20180612T002400_1-000-002.nc\n",
      "LIN-RS-01_2_RS92-GDP_002_20180122T120000_1-002-001.nc\n",
      "LIN-RS-01_2_RS92-GDP_002_20180613T180000_1-002-002.nc\n",
      "--------------------------------------------------\n",
      "Downloading first 2 files for demo purpose\n",
      "Download completed.\n",
      "--------------------------------------------------\n",
      "     Attribute                                              Value\n",
      "0  Conventions                                             CF-1.4\n",
      "1        title                RS92 GRUAN Data Product (Version 2)\n",
      "2  institution  MOL - Lindenberg Meteorological Observatory; D...\n",
      "3       source                                           RS92-SGP\n",
      "4      history  2018-06-11 21:30:51.000Z RS92-GDP: RS92 GRUAN ...\n",
      "--------------------------------------------------\n",
      "     Attribute                                              Value\n",
      "0  Conventions                                             CF-1.4\n",
      "1        title                RS92 GRUAN Data Product (Version 2)\n",
      "2  institution  MOL - Lindenberg Meteorological Observatory; D...\n",
      "3       source                                           RS92-SGP\n",
      "4      history  2018-01-03 12:37:10.000Z RS92-GDP: RS92 GRUAN ...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Download Gruan Data Product (GDP) through NOAA FTP\n",
    "ftp_dir_path=r'pub/data/gruan/processing/level2/RS92-GDP/version-002/LIN/2018'\n",
    "files=gp.search(ftp_dir_path=ftp_dir_path)\n",
    "print(f\"Found {len(files)} files in {ftp_dir_path}\")\n",
    "for file in files[:5]:\n",
    "    print(file)\n",
    "print(\"-----\"*10)\n",
    "print(\"Downloading first 2 files for demo purpose\")\n",
    "files=files[:2]\n",
    "for file in files:\n",
    "    gp.download(ftp_dir_path=ftp_dir_path, file_name=file)\n",
    "print(\"Download completed.\")\n",
    "print(\"-----\"*10)\n",
    "for file in files:\n",
    "    gdp=gp.read(download_folder+r'/ '[:-1]+file)\n",
    "    print(gdp.global_attrs.head())\n",
    "    print(\"-----\"*10)\n",
    "\n",
    "# Iterative script at code_examples\\download_gdp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2fce57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing API request ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 10:53:45,454 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2025-05-28 10:53:45,455 WARNING [2024-06-16T00:00:00] CDS API syntax is changed and some keys or parameter names may have also changed. To avoid requests failing, please use the \"Show API request code\" tool on the dataset Download Form to check you are using the correct syntax for your API request.\n",
      "2025-05-28 10:53:46,171 INFO Request ID is 1cee6683-13e9-4835-83c8-6c0deddbaf89\n",
      "2025-05-28 10:53:46,275 INFO status has been updated to accepted\n",
      "2025-05-28 10:55:02,255 INFO status has been updated to successful\n",
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Download GRUAN DATA through CDS API in csv format\n",
    "\n",
    "api_response_file = \"api_response.csv\"\n",
    "api_request = \"\"\"\n",
    "import cdsapi\n",
    "\n",
    "dataset = \"insitu-observations-gruan-reference-network\"\n",
    "request = {\n",
    "    \"variable\": [\n",
    "        \"air_temperature\",\n",
    "        \"relative_humidity\",\n",
    "        \"relative_humidity_effective_vertical_resolution\",\n",
    "        \"wind_speed\",\n",
    "        \"wind_from_direction\",\n",
    "        \"eastward_wind_speed\",\n",
    "        \"northward_wind_speed\",\n",
    "        \"shortwave_radiation\",\n",
    "        \"air_pressure\",\n",
    "        \"altitude\",\n",
    "        \"geopotential_height\",\n",
    "        \"frost_point_temperature\",\n",
    "        \"water_vapour_volume_mixing_ratio\",\n",
    "        \"vertical_speed_of_radiosonde\",\n",
    "        \"time_since_launch\"\n",
    "    ],\n",
    "    \"year\": \"2014\",\n",
    "    \"month\": \"10\",\n",
    "    \"day\": [\"14\"],\n",
    "    \"data_format\": \"csv\",\n",
    "    \"area\": [90, 0, 0, 90]\n",
    "}\n",
    "\n",
    "client = cdsapi.Client()\n",
    "\"\"\"+f\"\"\"\n",
    "target= r\"{download_folder}\\\\{api_response_file}\" # Change this to your desired output path\n",
    "client.retrieve(dataset, request, target)\n",
    "\n",
    "\"\"\"\n",
    "print(\"Executing API request ...\")\n",
    "gp.exec_request(api_request)\n",
    "print(\"-----\"*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3897e76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing API request ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 11:16:44,989 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2025-05-28 11:16:44,990 WARNING [2024-06-16T00:00:00] CDS API syntax is changed and some keys or parameter names may have also changed. To avoid requests failing, please use the \"Show API request code\" tool on the dataset Download Form to check you are using the correct syntax for your API request.\n",
      "2025-05-28 11:16:45,706 INFO Request ID is f5bfd683-46f5-40fb-bca0-50816aa87b21\n",
      "2025-05-28 11:16:45,809 INFO status has been updated to accepted\n",
      "2025-05-28 11:17:35,883 INFO status has been updated to successful\n",
      "                                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Download GRUAN DATA through CDS API in netCDF format\n",
    "\n",
    "api_response_file = \"api_response.nc\"\n",
    "api_request = \"\"\"\n",
    "import cdsapi\n",
    "\n",
    "dataset = \"insitu-observations-gruan-reference-network\"\n",
    "request = {\n",
    "    \"variable\": [\n",
    "        \"air_temperature\",\n",
    "        \"relative_humidity\",\n",
    "        \"relative_humidity_effective_vertical_resolution\",\n",
    "        \"wind_speed\",\n",
    "        \"wind_from_direction\",\n",
    "        \"eastward_wind_speed\",\n",
    "        \"northward_wind_speed\",\n",
    "        \"shortwave_radiation\",\n",
    "        \"air_pressure\",\n",
    "        \"altitude\",\n",
    "        \"geopotential_height\",\n",
    "        \"frost_point_temperature\",\n",
    "        \"water_vapour_volume_mixing_ratio\",\n",
    "        \"vertical_speed_of_radiosonde\",\n",
    "        \"time_since_launch\"\n",
    "    ],\n",
    "    \"year\": \"2014\",\n",
    "    \"month\": \"10\",\n",
    "    \"day\": [\"14\"],\n",
    "    \"data_format\": \"netcdf\",\n",
    "    \"area\": [90, 0, 0, 90]\n",
    "}\n",
    "\n",
    "client = cdsapi.Client()\n",
    "\"\"\"+f\"\"\"\n",
    "target= r\"{download_folder}\\\\{api_response_file}\" # Change this to your desired output path\n",
    "client.retrieve(dataset, request, target)\n",
    "\n",
    "\"\"\"\n",
    "print(\"Executing API request ...\")\n",
    "gp.exec_request(api_request)\n",
    "print(\"-----\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f1d15a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ce5ed3b",
   "metadata": {},
   "source": [
    "# MERGE and AGGREGATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f77b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDP RS41 spatial gridding\n",
    "file_path = r'gdp_demo_090625\\LIN-RS-01_2_RS41-GDP_001_20141209T120000_1-009-002.nc'\n",
    "gdp=gp.read(file_path)\n",
    "\n",
    "bin_column = 'press' # Choose the binning column (alt or press)\n",
    "target_columns = ['temp', 'rh']\n",
    "\n",
    "ggd = gp.spatial_gridding(gdp, bin_column, target_columns)\n",
    "\n",
    "# Plot original and gridded data\n",
    "for column in target_columns:\n",
    "    fig, ax1 = plt.subplots(figsize=(7, 6))\n",
    "    if bin_column == 'press':\n",
    "        ax1.set_yscale('log')\n",
    "        ax1.invert_yaxis()\n",
    "    ax1.scatter(gdp.data[column], gdp.data[bin_column], label='Original Data', alpha=0.5)\n",
    "    ax1.scatter(ggd.data[column], ggd.data[bin_column], label='Gridded Data', color='red', alpha=0.5)\n",
    "    ax1.fill_betweenx(gdp.data[bin_column], gdp.data[column] - gdp.data[column+'_uc'], gdp.data[column] + gdp.data[column+'_uc'], color='blue', alpha=0.2, label='Original Uncertainty')\n",
    "    ax1.fill_betweenx(ggd.data[bin_column], ggd.data[column] - ggd.data[column+'_uc'], ggd.data[column] + ggd.data[column+'_uc'], color='red', alpha=0.2, label='Gridded Uncertainty')\n",
    "    ax1.set_xlabel(f'{column.capitalize()} {gdp.variables_attrs[gdp.variables_attrs['variable'] == column]['units'].values[0]}')\n",
    "    ax1.set_ylabel(f'{bin_column.capitalize()} {gdp.variables_attrs[gdp.variables_attrs['variable'] == bin_column]['units'].values[0]}')\n",
    "    ax1.legend()\n",
    "    long_name= gdp.variables_attrs[gdp.variables_attrs['variable'] == column]['long_name'].values[0]\n",
    "    ax1.set_title(f'{long_name} Mandatory Levels Spatial Gridding')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38db29cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading GDPs: 100%|██████████| 50/50 [01:10<00:00,  1.42s/it]\n",
      "Spatial Gridding: 100%|██████████| 50/50 [00:01<00:00, 37.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# GDP RS41 temporal gridding\n",
    "\n",
    "# Read multiple GDP files\n",
    "gdp_folder=r'gdp_demo_090625\\products_RS41-GDP-1_LIN_2017' # Path to the folder\n",
    "gdp_files = [os.path.join(gdp_folder, f) for f in os.listdir(gdp_folder) if f.endswith('.nc')]\n",
    "gdps=[]\n",
    "for file in tqdm(gdp_files[:50] , desc=\"Reading GDPs\"):\n",
    "    gdps.append(gp.read(file))\n",
    "\n",
    "# Uniform Spatial gridding accross multiple GDPs\n",
    "ggds=[]\n",
    "target_columns = ['temp', 'rh']\n",
    "for gdp in tqdm(gdps, desc=\"Spatial Gridding\"):\n",
    "    ggd = gp.spatial_gridding(gdp, 'press', target_columns, mandatory_levels_flag=True)\n",
    "    ggds.append(ggd)\n",
    "\n",
    "# Temporal gridding\n",
    "tggd = gp.temporal_gridding(ggds, target_columns, bin_size=7, lvl_column='press')\n",
    "\n",
    "# Plotting the temporal gridded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4cf002",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lvl in tggd.data['mand_lvl'].unique():\n",
    "    # NOT WORKING YET\n",
    "    # need to fix all the gridding methods and add a just merge method\n",
    "    mggd=pd.DataFrame()\n",
    "    for ggd in ggds:\n",
    "        start_time_str = ggd.metadata[ggd.metadata['Attribute'] == 'g.Measurement.StartTime']['Value'].values[0]\n",
    "        start_time = datetime.strptime(start_time_str, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        ggd_data = ggd.data.copy()\n",
    "        ggd_data['time'] = start_time\n",
    "        mggd = pd.concat([mggd, ggd_data[ggd_data['mand_lvl'] == lvl]], ignore_index=True)\n",
    "    \n",
    "    for column in target_columns:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.plot(mggd['time'], mggd[column], marker='o', linestyle='-', label=column)\n",
    "        ax.plot(tggd.data[tggd.data['mand_lvl'] == lvl]['time'], tggd.data[tggd.data['mand_lvl'] == lvl][column], marker='x', linestyle='--', color='red', label=f'Temporal Gridded {column}')\n",
    "        ax.fill_between(mggd['time'], mggd[column] - mggd[column+'_uc'], mggd[column] + mggd[column+'_uc'], alpha=0.2)\n",
    "        ax.set_xlabel('Time')\n",
    "        #ax.set_ylabel(f'{column.capitalize()} {ggd.variables_attrs[ggd.variables_attrs[\"variable\"] == column][\"units\"].values[0]}')\n",
    "        ax.set_title(f'Temporal Gridded {column} at Mandatory Level {lvl}')\n",
    "        ax.legend()\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    #print(mggd.columns)\n",
    "    #print(mggd.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20c10459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ggds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aedc0ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_bin</th>\n",
       "      <th>press</th>\n",
       "      <th>temp</th>\n",
       "      <th>rh</th>\n",
       "      <th>mand_lvl</th>\n",
       "      <th>time</th>\n",
       "      <th>temp_uc_ucor_avg</th>\n",
       "      <th>temp_var</th>\n",
       "      <th>temp_uc_sc</th>\n",
       "      <th>temp_uc_ucor</th>\n",
       "      <th>temp_cor</th>\n",
       "      <th>temp_uc</th>\n",
       "      <th>rh_uc_ucor_avg</th>\n",
       "      <th>rh_var</th>\n",
       "      <th>rh_uc_sc</th>\n",
       "      <th>rh_uc_ucor</th>\n",
       "      <th>rh_cor</th>\n",
       "      <th>rh_uc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>5.972275</td>\n",
       "      <td>216.646744</td>\n",
       "      <td>1.314128</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-01-06 10:45:18.235</td>\n",
       "      <td>0.137911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137911</td>\n",
       "      <td>0.079224</td>\n",
       "      <td>0.159047</td>\n",
       "      <td>0.052588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052588</td>\n",
       "      <td>2.098747</td>\n",
       "      <td>2.099405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.5</td>\n",
       "      <td>7.040342</td>\n",
       "      <td>212.783279</td>\n",
       "      <td>1.692838</td>\n",
       "      <td>7</td>\n",
       "      <td>2017-01-06 10:45:18.235</td>\n",
       "      <td>0.072011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072011</td>\n",
       "      <td>0.080095</td>\n",
       "      <td>0.107707</td>\n",
       "      <td>0.016289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016289</td>\n",
       "      <td>2.191129</td>\n",
       "      <td>2.191190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.5</td>\n",
       "      <td>7.616255</td>\n",
       "      <td>219.176804</td>\n",
       "      <td>1.553187</td>\n",
       "      <td>7</td>\n",
       "      <td>2017-01-06 10:45:18.235</td>\n",
       "      <td>0.131919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121910</td>\n",
       "      <td>0.179623</td>\n",
       "      <td>0.189554</td>\n",
       "      <td>0.261143</td>\n",
       "      <td>0.017718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017718</td>\n",
       "      <td>1.175712</td>\n",
       "      <td>1.175845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.5</td>\n",
       "      <td>11.141134</td>\n",
       "      <td>201.235672</td>\n",
       "      <td>3.311255</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-01-06 10:45:18.235</td>\n",
       "      <td>0.125646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125646</td>\n",
       "      <td>0.083302</td>\n",
       "      <td>0.150752</td>\n",
       "      <td>0.038273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038273</td>\n",
       "      <td>2.621775</td>\n",
       "      <td>2.622054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "      <td>11.370716</td>\n",
       "      <td>211.254333</td>\n",
       "      <td>2.151662</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-01-06 10:45:18.235</td>\n",
       "      <td>0.080735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097381</td>\n",
       "      <td>0.126496</td>\n",
       "      <td>0.131397</td>\n",
       "      <td>0.182391</td>\n",
       "      <td>0.023049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023049</td>\n",
       "      <td>1.485718</td>\n",
       "      <td>1.485896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_bin      press        temp        rh  mand_lvl  \\\n",
       "0       3.5   5.972275  216.646744  1.314128         5   \n",
       "1       3.5   7.040342  212.783279  1.692838         7   \n",
       "2       3.5   7.616255  219.176804  1.553187         7   \n",
       "3       3.5  11.141134  201.235672  3.311255        10   \n",
       "4       3.5  11.370716  211.254333  2.151662        10   \n",
       "\n",
       "                     time  temp_uc_ucor_avg  temp_var  temp_uc_sc  \\\n",
       "0 2017-01-06 10:45:18.235          0.137911       0.0    0.000000   \n",
       "1 2017-01-06 10:45:18.235          0.072011       0.0    0.000000   \n",
       "2 2017-01-06 10:45:18.235          0.131919       0.0    0.121910   \n",
       "3 2017-01-06 10:45:18.235          0.125646       0.0    0.000000   \n",
       "4 2017-01-06 10:45:18.235          0.080735       0.0    0.097381   \n",
       "\n",
       "   temp_uc_ucor  temp_cor   temp_uc  rh_uc_ucor_avg  rh_var  rh_uc_sc  \\\n",
       "0      0.137911  0.079224  0.159047        0.052588     0.0       0.0   \n",
       "1      0.072011  0.080095  0.107707        0.016289     0.0       0.0   \n",
       "2      0.179623  0.189554  0.261143        0.017718     0.0       0.0   \n",
       "3      0.125646  0.083302  0.150752        0.038273     0.0       0.0   \n",
       "4      0.126496  0.131397  0.182391        0.023049     0.0       0.0   \n",
       "\n",
       "   rh_uc_ucor    rh_cor     rh_uc  \n",
       "0    0.052588  2.098747  2.099405  \n",
       "1    0.016289  2.191129  2.191190  \n",
       "2    0.017718  1.175712  1.175845  \n",
       "3    0.038273  2.621775  2.622054  \n",
       "4    0.023049  1.485718  1.485896  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tggd.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd50804",
   "metadata": {},
   "source": [
    "## PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e826a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "778b5be2",
   "metadata": {},
   "source": [
    "# DATA VISUALIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a041fe6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
