{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "254cd048",
   "metadata": {},
   "source": [
    "# GRUANpy Proof of Concept\n",
    "\n",
    "GRUANpy is a python toolkit to facilitate the analysis of GRUAN data. It includes several functionalities and is easily extensible thanks to its structure based on the inclusion of different data models and helper classes that provide specialized methods for different types of purposes. The different functions can also be executed in succession in order to create real data pipelines that allow a large variety of outputs.\n",
    "\n",
    "Here is a list of the main features identified so far:\n",
    "- download, the ability to download data of interest\n",
    "- merge, the ability to merge data from different products\n",
    "- aggregation, the ability to aggregate different observations and lower the resolution of the data (respecting the GRUAN principles in uncertainty processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edef7619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo setup\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from gruanpy import GRUANpy\n",
    "from datetime import datetime\n",
    "download_folder=r\"gdp_demo_090625\"\n",
    "gp = GRUANpy(download_folder=download_folder)\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d539f1",
   "metadata": {},
   "source": [
    "## DOWNLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab868b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75 files in pub/data/gruan/processing/level2/RS92-GDP/version-002/LIN/2018\n",
      "LIN-RS-01_2_RS92-GDP_002_20180611T180000_1-002-001.nc\n",
      "LIN-RS-01_2_RS92-GDP_002_20180103T000000_1-002-002.nc\n",
      "LIN-RS-01_2_RS92-GDP_002_20180612T002400_1-000-002.nc\n",
      "LIN-RS-01_2_RS92-GDP_002_20180122T120000_1-002-001.nc\n",
      "LIN-RS-01_2_RS92-GDP_002_20180613T180000_1-002-002.nc\n",
      "--------------------------------------------------\n",
      "Downloading first 2 files for demo purpose\n",
      "Download completed.\n",
      "--------------------------------------------------\n",
      "     Attribute                                              Value\n",
      "0  Conventions                                             CF-1.4\n",
      "1        title                RS92 GRUAN Data Product (Version 2)\n",
      "2  institution  MOL - Lindenberg Meteorological Observatory; D...\n",
      "3       source                                           RS92-SGP\n",
      "4      history  2018-06-11 21:30:51.000Z RS92-GDP: RS92 GRUAN ...\n",
      "--------------------------------------------------\n",
      "     Attribute                                              Value\n",
      "0  Conventions                                             CF-1.4\n",
      "1        title                RS92 GRUAN Data Product (Version 2)\n",
      "2  institution  MOL - Lindenberg Meteorological Observatory; D...\n",
      "3       source                                           RS92-SGP\n",
      "4      history  2018-01-03 12:37:10.000Z RS92-GDP: RS92 GRUAN ...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Download Gruan Data Product (GDP) through NOAA FTP\n",
    "ftp_dir_path=r'pub/data/gruan/processing/level2/RS92-GDP/version-002/LIN/2018'\n",
    "files=gp.search(ftp_dir_path=ftp_dir_path)\n",
    "print(f\"Found {len(files)} files in {ftp_dir_path}\")\n",
    "for file in files[:5]:\n",
    "    print(file)\n",
    "print(\"-----\"*10)\n",
    "print(\"Downloading first 2 files for demo purpose\")\n",
    "files=files[:2]\n",
    "for file in files:\n",
    "    gp.download(ftp_dir_path=ftp_dir_path, file_name=file)\n",
    "print(\"Download completed.\")\n",
    "print(\"-----\"*10)\n",
    "for file in files:\n",
    "    gdp=gp.read(download_folder+r'/ '[:-1]+file)\n",
    "    print(gdp.global_attrs.head())\n",
    "    print(\"-----\"*10)\n",
    "\n",
    "# Iterative script at code_examples\\download_gdp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2fce57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing API request ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 10:53:45,454 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2025-05-28 10:53:45,455 WARNING [2024-06-16T00:00:00] CDS API syntax is changed and some keys or parameter names may have also changed. To avoid requests failing, please use the \"Show API request code\" tool on the dataset Download Form to check you are using the correct syntax for your API request.\n",
      "2025-05-28 10:53:46,171 INFO Request ID is 1cee6683-13e9-4835-83c8-6c0deddbaf89\n",
      "2025-05-28 10:53:46,275 INFO status has been updated to accepted\n",
      "2025-05-28 10:55:02,255 INFO status has been updated to successful\n",
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Download GRUAN DATA through CDS API in csv format\n",
    "\n",
    "api_response_file = \"api_response.csv\"\n",
    "api_request = \"\"\"\n",
    "import cdsapi\n",
    "\n",
    "dataset = \"insitu-observations-gruan-reference-network\"\n",
    "request = {\n",
    "    \"variable\": [\n",
    "        \"air_temperature\",\n",
    "        \"relative_humidity\",\n",
    "        \"relative_humidity_effective_vertical_resolution\",\n",
    "        \"wind_speed\",\n",
    "        \"wind_from_direction\",\n",
    "        \"eastward_wind_speed\",\n",
    "        \"northward_wind_speed\",\n",
    "        \"shortwave_radiation\",\n",
    "        \"air_pressure\",\n",
    "        \"altitude\",\n",
    "        \"geopotential_height\",\n",
    "        \"frost_point_temperature\",\n",
    "        \"water_vapour_volume_mixing_ratio\",\n",
    "        \"vertical_speed_of_radiosonde\",\n",
    "        \"time_since_launch\"\n",
    "    ],\n",
    "    \"year\": \"2014\",\n",
    "    \"month\": \"10\",\n",
    "    \"day\": [\"14\"],\n",
    "    \"data_format\": \"csv\",\n",
    "    \"area\": [90, 0, 0, 90]\n",
    "}\n",
    "\n",
    "client = cdsapi.Client()\n",
    "\"\"\"+f\"\"\"\n",
    "target= r\"{download_folder}\\\\{api_response_file}\" # Change this to your desired output path\n",
    "client.retrieve(dataset, request, target)\n",
    "\n",
    "\"\"\"\n",
    "print(\"Executing API request ...\")\n",
    "gp.exec_request(api_request)\n",
    "print(\"-----\"*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3897e76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing API request ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 11:16:44,989 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2025-05-28 11:16:44,990 WARNING [2024-06-16T00:00:00] CDS API syntax is changed and some keys or parameter names may have also changed. To avoid requests failing, please use the \"Show API request code\" tool on the dataset Download Form to check you are using the correct syntax for your API request.\n",
      "2025-05-28 11:16:45,706 INFO Request ID is f5bfd683-46f5-40fb-bca0-50816aa87b21\n",
      "2025-05-28 11:16:45,809 INFO status has been updated to accepted\n",
      "2025-05-28 11:17:35,883 INFO status has been updated to successful\n",
      "                                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Download GRUAN DATA through CDS API in netCDF format\n",
    "\n",
    "api_response_file = \"api_response.nc\"\n",
    "api_request = \"\"\"\n",
    "import cdsapi\n",
    "\n",
    "dataset = \"insitu-observations-gruan-reference-network\"\n",
    "request = {\n",
    "    \"variable\": [\n",
    "        \"air_temperature\",\n",
    "        \"relative_humidity\",\n",
    "        \"relative_humidity_effective_vertical_resolution\",\n",
    "        \"wind_speed\",\n",
    "        \"wind_from_direction\",\n",
    "        \"eastward_wind_speed\",\n",
    "        \"northward_wind_speed\",\n",
    "        \"shortwave_radiation\",\n",
    "        \"air_pressure\",\n",
    "        \"altitude\",\n",
    "        \"geopotential_height\",\n",
    "        \"frost_point_temperature\",\n",
    "        \"water_vapour_volume_mixing_ratio\",\n",
    "        \"vertical_speed_of_radiosonde\",\n",
    "        \"time_since_launch\"\n",
    "    ],\n",
    "    \"year\": \"2014\",\n",
    "    \"month\": \"10\",\n",
    "    \"day\": [\"14\"],\n",
    "    \"data_format\": \"netcdf\",\n",
    "    \"area\": [90, 0, 0, 90]\n",
    "}\n",
    "\n",
    "client = cdsapi.Client()\n",
    "\"\"\"+f\"\"\"\n",
    "target= r\"{download_folder}\\\\{api_response_file}\" # Change this to your desired output path\n",
    "client.retrieve(dataset, request, target)\n",
    "\n",
    "\"\"\"\n",
    "print(\"Executing API request ...\")\n",
    "gp.exec_request(api_request)\n",
    "print(\"-----\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f1d15a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ce5ed3b",
   "metadata": {},
   "source": [
    "# MERGE and AGGREGATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f77b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDP RS41 spatial gridding\n",
    "file_path = r'gdp_demo_090625\\LIN-RS-01_2_RS41-GDP_001_20141209T120000_1-009-002.nc'\n",
    "gdp=gp.read(file_path)\n",
    "\n",
    "bin_column = 'press' # Choose the binning column (alt or press)\n",
    "target_columns = ['temp', 'rh']\n",
    "\n",
    "ggd = gp.spatial_gridding(gdp, bin_column, target_columns)\n",
    "\n",
    "# Plot original and gridded data\n",
    "for column in target_columns:\n",
    "    fig, ax1 = plt.subplots(figsize=(7, 6))\n",
    "    if bin_column == 'press':\n",
    "        ax1.set_yscale('log')\n",
    "        ax1.invert_yaxis()\n",
    "    ax1.scatter(gdp.data[column], gdp.data[bin_column], label='Original Data', alpha=0.5)\n",
    "    ax1.scatter(ggd.data[column], ggd.data[bin_column], label='Gridded Data', color='red', alpha=0.5)\n",
    "    ax1.fill_betweenx(gdp.data[bin_column], gdp.data[column] - gdp.data[column+'_uc'], gdp.data[column] + gdp.data[column+'_uc'], color='blue', alpha=0.2, label='Original Uncertainty')\n",
    "    ax1.fill_betweenx(ggd.data[bin_column], ggd.data[column] - ggd.data[column+'_uc'], ggd.data[column] + ggd.data[column+'_uc'], color='red', alpha=0.2, label='Gridded Uncertainty')\n",
    "    ax1.set_xlabel(f'{column.capitalize()} {gdp.variables_attrs[gdp.variables_attrs['variable'] == column]['units'].values[0]}')\n",
    "    ax1.set_ylabel(f'{bin_column.capitalize()} {gdp.variables_attrs[gdp.variables_attrs['variable'] == bin_column]['units'].values[0]}')\n",
    "    ax1.legend()\n",
    "    long_name= gdp.variables_attrs[gdp.variables_attrs['variable'] == column]['long_name'].values[0]\n",
    "    ax1.set_title(f'{long_name} Mandatory Levels Spatial Gridding')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1559fe54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading GDPs: 100%|██████████| 50/50 [01:08<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "# GDP RS41 temporal gridding\n",
    "\n",
    "# Read multiple GDP files\n",
    "gdp_folder=r'C:\\Users\\tomma\\Documents\\SDC\\Repos\\GRUAN_EDA\\gdp\\products_RS41-GDP-1_LIN_2017'#gdp_demo_090625\\products_RS41-GDP-1_LIN_2017' # Path to the folder\n",
    "gdp_files = [os.path.join(gdp_folder, f) for f in os.listdir(gdp_folder) if f.endswith('.nc')]\n",
    "gdps=[]\n",
    "for file in tqdm(gdp_files[:50] , desc=\"Reading GDPs\"):\n",
    "    gdps.append(gp.read(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "988e5c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spatial Gridding: 100%|██████████| 50/50 [00:01<00:00, 28.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# Uniform Spatial gridding accross multiple GDPs\n",
    "ggds=[]\n",
    "target_columns = ['temp', 'rh']\n",
    "for gdp in tqdm(gdps, desc=\"Spatial Gridding\"):\n",
    "    ggd = gp.spatial_gridding(gdp, 'press', target_columns, mandatory_levels_flag=True)\n",
    "    ggds.append(ggd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b82d5217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging Gridded Data: 100%|██████████| 50/50 [00:00<00:00, 899.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Merge all gridded data\n",
    "mggd=pd.DataFrame()\n",
    "for ggd in tqdm(ggds, desc=\"Merging Gridded Data\"):\n",
    "    start_time_str = ggd.metadata[ggd.metadata['Attribute'] == 'g.Measurement.StartTime']['Value'].values[0]\n",
    "    start_time = datetime.strptime(start_time_str, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    ggd_data = ggd.data.copy()\n",
    "    ggd_data['time'] = start_time\n",
    "    mggd = pd.concat([mggd, ggd_data], ignore_index=True)\n",
    "\n",
    "# Plotting the merged gridded data\n",
    "for column in target_columns:\n",
    "    # Separate data into day and night based on time (e.g., 6:00-18:00 as day, else night)\n",
    "    mand_lvl_val = 1000\n",
    "    subset = mggd[mggd['mand_lvl'] == mand_lvl_val].copy()\n",
    "    subset['hour'] = subset['time'].dt.hour\n",
    "    day_data = subset[(subset['hour'] >= 6) & (subset['hour'] < 18)]\n",
    "    night_data = subset[(subset['hour'] < 6) | (subset['hour'] >= 18)]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(day_data['time'], day_data[column], marker='o', linestyle='-', label=f'{column} (Day)')\n",
    "    ax.plot(night_data['time'], night_data[column], marker='x', linestyle='--', label=f'{column} (Night)')\n",
    "    ax.fill_between(day_data['time'], day_data[column] - day_data[column + '_uc'], day_data[column] + day_data[column + '_uc'], alpha=0.2, label='Day Uncertainty')\n",
    "    ax.fill_between(night_data['time'], night_data[column] - night_data[column + '_uc'], night_data[column] + night_data[column + '_uc'], alpha=0.2, label='Night Uncertainty')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel(column.capitalize())\n",
    "    ax.set_title(f'{column.capitalize()} at Mandatory Level {mand_lvl_val} Over Time (Day vs Night)')\n",
    "    ax.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d802836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mand_lvl</th>\n",
       "      <th>temp</th>\n",
       "      <th>rh</th>\n",
       "      <th>press</th>\n",
       "      <th>temp_uc_ucor_avg</th>\n",
       "      <th>temp_var</th>\n",
       "      <th>temp_uc_ucor</th>\n",
       "      <th>temp_uc_scor</th>\n",
       "      <th>temp_uc_tcor</th>\n",
       "      <th>temp_uc</th>\n",
       "      <th>rh_uc_ucor_avg</th>\n",
       "      <th>rh_var</th>\n",
       "      <th>rh_uc_ucor</th>\n",
       "      <th>rh_uc_scor</th>\n",
       "      <th>rh_uc_tcor</th>\n",
       "      <th>rh_uc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>216.646744</td>\n",
       "      <td>1.314128</td>\n",
       "      <td>5.972275</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.137854</td>\n",
       "      <td>0.137911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079224</td>\n",
       "      <td>0.159047</td>\n",
       "      <td>0.049452</td>\n",
       "      <td>0.017888</td>\n",
       "      <td>0.052588</td>\n",
       "      <td>0</td>\n",
       "      <td>2.098747</td>\n",
       "      <td>2.099405</td>\n",
       "      <td>2017-01-02 22:45:18.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>212.783279</td>\n",
       "      <td>1.692838</td>\n",
       "      <td>7.040342</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>0.071990</td>\n",
       "      <td>0.072011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080095</td>\n",
       "      <td>0.107707</td>\n",
       "      <td>0.013101</td>\n",
       "      <td>0.009679</td>\n",
       "      <td>0.016289</td>\n",
       "      <td>0</td>\n",
       "      <td>2.191129</td>\n",
       "      <td>2.191190</td>\n",
       "      <td>2017-01-02 22:45:18.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>201.235672</td>\n",
       "      <td>3.311255</td>\n",
       "      <td>11.141134</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.125640</td>\n",
       "      <td>0.125646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083302</td>\n",
       "      <td>0.150752</td>\n",
       "      <td>0.020167</td>\n",
       "      <td>0.032528</td>\n",
       "      <td>0.038273</td>\n",
       "      <td>0</td>\n",
       "      <td>2.621775</td>\n",
       "      <td>2.622054</td>\n",
       "      <td>2017-01-02 22:45:18.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>199.591782</td>\n",
       "      <td>5.000197</td>\n",
       "      <td>19.690186</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.147285</td>\n",
       "      <td>0.147290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.169475</td>\n",
       "      <td>0.028827</td>\n",
       "      <td>0.071766</td>\n",
       "      <td>0.077339</td>\n",
       "      <td>0</td>\n",
       "      <td>2.801397</td>\n",
       "      <td>2.802464</td>\n",
       "      <td>2017-01-02 22:45:18.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>199.036987</td>\n",
       "      <td>5.941062</td>\n",
       "      <td>31.834671</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.081231</td>\n",
       "      <td>0.081233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083982</td>\n",
       "      <td>0.116841</td>\n",
       "      <td>0.028855</td>\n",
       "      <td>0.042116</td>\n",
       "      <td>0.051053</td>\n",
       "      <td>0</td>\n",
       "      <td>2.803793</td>\n",
       "      <td>2.804258</td>\n",
       "      <td>2017-01-02 22:45:18.235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mand_lvl        temp        rh      press  temp_uc_ucor_avg  temp_var  \\\n",
       "0         5  216.646744  1.314128   5.972275          0.003949  0.137854   \n",
       "1         7  212.783279  1.692838   7.040342          0.001748  0.071990   \n",
       "2        10  201.235672  3.311255  11.141134          0.001247  0.125640   \n",
       "3        20  199.591782  5.000197  19.690186          0.001235  0.147285   \n",
       "4        30  199.036987  5.941062  31.834671          0.000644  0.081231   \n",
       "\n",
       "   temp_uc_ucor  temp_uc_scor  temp_uc_tcor   temp_uc  rh_uc_ucor_avg  \\\n",
       "0      0.137911           0.0      0.079224  0.159047        0.049452   \n",
       "1      0.072011           0.0      0.080095  0.107707        0.013101   \n",
       "2      0.125646           0.0      0.083302  0.150752        0.020167   \n",
       "3      0.147290           0.0      0.083829  0.169475        0.028827   \n",
       "4      0.081233           0.0      0.083982  0.116841        0.028855   \n",
       "\n",
       "     rh_var  rh_uc_ucor  rh_uc_scor  rh_uc_tcor     rh_uc  \\\n",
       "0  0.017888    0.052588           0    2.098747  2.099405   \n",
       "1  0.009679    0.016289           0    2.191129  2.191190   \n",
       "2  0.032528    0.038273           0    2.621775  2.622054   \n",
       "3  0.071766    0.077339           0    2.801397  2.802464   \n",
       "4  0.042116    0.051053           0    2.803793  2.804258   \n",
       "\n",
       "                     time  \n",
       "0 2017-01-02 22:45:18.235  \n",
       "1 2017-01-02 22:45:18.235  \n",
       "2 2017-01-02 22:45:18.235  \n",
       "3 2017-01-02 22:45:18.235  \n",
       "4 2017-01-02 22:45:18.235  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mggd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "920d7e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal gridding from scratch\n",
    "\n",
    "bin_size = 7 # Size of the time bin in days\n",
    "mggd[bin] = (mggd['time'].dt.day // bin_size) * bin_size + bin_size / 2\n",
    "first_data = mggd['time'].min()\n",
    "tggd = mggd.groupby(['mand_lvl', 'time_bin'])[target_columns].mean().reset_index() # 3.12\n",
    "tggd['time'] = pd.to_datetime(tggd['time_bin'], unit='D', origin=first_data)\n",
    "for col in target_columns:\n",
    "    tggd[col + '_uc_ucor_avg'] = mggd.groupby([bin,'mand_lvl'])[col + '_uc_ucor'].apply(\n",
    "                lambda x: (((x**2).sum())**0.5)/len(x)\n",
    "                ).reset_index(drop=True) #3.13\n",
    "    tggd[col + '_var'] = mggd.groupby([bin,'mand_lvl'])[col].apply(\n",
    "                lambda x: ((((x-x.mean())**2).sum())/(len(x)*max((len(x)-1),1)))**0.5\n",
    "                ).reset_index(drop=True) #3.14\n",
    "    tggd[col + '_uc_sc']=mggd.groupby([bin,'mand_lvl'])[col + '_uc_scor'].apply(\n",
    "                lambda x: (((x**2).sum())**0.5)/len(x)\n",
    "                ).reset_index(drop=True) #3.15\n",
    "    tggd[col + '_uc_ucor']=(\n",
    "        tggd[col+'_uc_ucor_avg']**2 + tggd[col + '_var']**2 + tggd[col + '_uc_sc']**2)**0.5 #3.16\n",
    "    tggd[col + '_cor']=mggd.groupby([bin,'mand_lvl'])[col + '_uc_tcor'].mean().reset_index(drop=True) #3.17\n",
    "    tggd[col+'_uc']=(\n",
    "        tggd[col+'_uc_ucor']**2 + tggd[col+'_cor']**2)**0.5 #3.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ec779c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mand_lvl</th>\n",
       "      <th>time_bin</th>\n",
       "      <th>temp</th>\n",
       "      <th>rh</th>\n",
       "      <th>time</th>\n",
       "      <th>temp_uc_ucor_avg</th>\n",
       "      <th>temp_var</th>\n",
       "      <th>temp_uc_sc</th>\n",
       "      <th>temp_uc_ucor</th>\n",
       "      <th>temp_cor</th>\n",
       "      <th>temp_uc</th>\n",
       "      <th>rh_uc_ucor_avg</th>\n",
       "      <th>rh_var</th>\n",
       "      <th>rh_uc_sc</th>\n",
       "      <th>rh_uc_ucor</th>\n",
       "      <th>rh_cor</th>\n",
       "      <th>rh_uc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>10.5</td>\n",
       "      <td>236.506180</td>\n",
       "      <td>0.199481</td>\n",
       "      <td>2017-01-12 12:00:00</td>\n",
       "      <td>0.113402</td>\n",
       "      <td>4.317035</td>\n",
       "      <td>0.067530</td>\n",
       "      <td>4.319052</td>\n",
       "      <td>0.246014</td>\n",
       "      <td>4.326053</td>\n",
       "      <td>0.011174</td>\n",
       "      <td>0.208364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208664</td>\n",
       "      <td>1.510194</td>\n",
       "      <td>1.524542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>24.5</td>\n",
       "      <td>233.541946</td>\n",
       "      <td>0.493441</td>\n",
       "      <td>2017-01-26 12:00:00</td>\n",
       "      <td>0.033854</td>\n",
       "      <td>2.295907</td>\n",
       "      <td>0.046920</td>\n",
       "      <td>2.296635</td>\n",
       "      <td>0.145872</td>\n",
       "      <td>2.301263</td>\n",
       "      <td>0.008353</td>\n",
       "      <td>0.187165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187351</td>\n",
       "      <td>1.387363</td>\n",
       "      <td>1.399956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>232.249100</td>\n",
       "      <td>0.499769</td>\n",
       "      <td>2017-01-05 12:00:00</td>\n",
       "      <td>0.042164</td>\n",
       "      <td>2.873644</td>\n",
       "      <td>0.042834</td>\n",
       "      <td>2.874272</td>\n",
       "      <td>0.125313</td>\n",
       "      <td>2.877003</td>\n",
       "      <td>0.007464</td>\n",
       "      <td>0.329356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.329440</td>\n",
       "      <td>1.601413</td>\n",
       "      <td>1.634948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>10.5</td>\n",
       "      <td>224.368484</td>\n",
       "      <td>0.900499</td>\n",
       "      <td>2017-01-12 12:00:00</td>\n",
       "      <td>0.052329</td>\n",
       "      <td>1.496945</td>\n",
       "      <td>0.036161</td>\n",
       "      <td>1.498296</td>\n",
       "      <td>0.110590</td>\n",
       "      <td>1.502372</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.441035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.441328</td>\n",
       "      <td>1.913264</td>\n",
       "      <td>1.963505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>233.200150</td>\n",
       "      <td>0.622524</td>\n",
       "      <td>2017-01-19 12:00:00</td>\n",
       "      <td>0.023436</td>\n",
       "      <td>0.962533</td>\n",
       "      <td>0.032480</td>\n",
       "      <td>0.963366</td>\n",
       "      <td>0.109934</td>\n",
       "      <td>0.969618</td>\n",
       "      <td>0.013163</td>\n",
       "      <td>0.455913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.456103</td>\n",
       "      <td>2.020304</td>\n",
       "      <td>2.071149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mand_lvl  time_bin        temp        rh                time  \\\n",
       "0         3      10.5  236.506180  0.199481 2017-01-12 12:00:00   \n",
       "1         3      24.5  233.541946  0.493441 2017-01-26 12:00:00   \n",
       "2         5       3.5  232.249100  0.499769 2017-01-05 12:00:00   \n",
       "3         5      10.5  224.368484  0.900499 2017-01-12 12:00:00   \n",
       "4         5      17.5  233.200150  0.622524 2017-01-19 12:00:00   \n",
       "\n",
       "   temp_uc_ucor_avg  temp_var  temp_uc_sc  temp_uc_ucor  temp_cor   temp_uc  \\\n",
       "0          0.113402  4.317035    0.067530      4.319052  0.246014  4.326053   \n",
       "1          0.033854  2.295907    0.046920      2.296635  0.145872  2.301263   \n",
       "2          0.042164  2.873644    0.042834      2.874272  0.125313  2.877003   \n",
       "3          0.052329  1.496945    0.036161      1.498296  0.110590  1.502372   \n",
       "4          0.023436  0.962533    0.032480      0.963366  0.109934  0.969618   \n",
       "\n",
       "   rh_uc_ucor_avg    rh_var  rh_uc_sc  rh_uc_ucor    rh_cor     rh_uc  \n",
       "0        0.011174  0.208364       0.0    0.208664  1.510194  1.524542  \n",
       "1        0.008353  0.187165       0.0    0.187351  1.387363  1.399956  \n",
       "2        0.007464  0.329356       0.0    0.329440  1.601413  1.634948  \n",
       "3        0.016069  0.441035       0.0    0.441328  1.913264  1.963505  \n",
       "4        0.013163  0.455913       0.0    0.456103  2.020304  2.071149  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tggd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e74054a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(851, 18) (89, 17)\n"
     ]
    }
   ],
   "source": [
    "print(mggd.shape,tggd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd50804",
   "metadata": {},
   "source": [
    "## PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e826a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "778b5be2",
   "metadata": {},
   "source": [
    "# DATA VISUALIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a041fe6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
